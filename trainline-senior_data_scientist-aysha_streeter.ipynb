{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6d418d-bfa8-457c-b031-aea601d432b6",
   "metadata": {},
   "source": [
    "    SCRIPT:  trainline-senior_data_scientist-case_study-aysha_streeter\n",
    "\n",
    "    AUTHOR:  Aysha Streeter <aysha.streeter@outlook.com>\n",
    "\n",
    "    DATE:    25th November 2025 @ 15:30 to 16:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ae2df-4530-40ef-94da-354de5beb162",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f65076-cdac-4350-a396-ca9591fdcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Visualisation\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Modelling\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad450e-346e-47bf-aaa3-9d212ebd9c43",
   "metadata": {},
   "source": [
    "# AIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0073111f-e7dd-4f44-944d-b1cb6111dcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"300\"\n",
       "            src=\"Data Scientist - Case Study Task.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x27da0722870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interview task pdf\n",
    "IFrame('Data Scientist - Case Study Task.pdf', width = 900, height = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd78f46-1343-4e6a-b985-5613cbb1fe35",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb0c0a5-6806-4dcd-864a-25aa22d0d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "# Displaying all columns.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_colwidth = 1000\n",
    "# Displaying all rows.\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf479227-a6d9-4e79-82d1-48cf3bdd1550",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80592193-acb2-488d-8263-9364a41a8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing provided datasets.\n",
    "df_sales = pd.read_csv('sales.csv', index_col = 0)\n",
    "df_stations = pd.read_csv('stations.csv', index_col = 0)\n",
    "\n",
    "# Importing lookups.\n",
    "df_postcodes = pd.read_csv('lookups/lookup_postcodes.csv', low_memory = False)\n",
    "df_coastal = pd.read_csv('lookups/lookup_coastal.csv')\n",
    "df_bua =  pd.read_csv('lookups/lookup_bua.csv', encoding = 'cp1252', low_memory = False)\n",
    "df_rgn = pd.read_csv('lookups/lookup_rgn.csv')\n",
    "df_ru11ind = pd.read_csv('lookups/lookup_ru11ind.csv')\n",
    "with open(\"lookups/lookup_holidays.json\") as f:\n",
    "    data_holidays = json.load(f)\n",
    "with open(\"lookups/lookup_strikes.json\") as f:\n",
    "    data_strikes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a2145-631d-45f7-99ca-b7f7f4d05c31",
   "metadata": {},
   "source": [
    "# QUALITY CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecbfb834-d374-4fa1-83b8-d98a28de079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a list of dataframes so relevant checks applied to both.\n",
    "dataframes = [df_sales, df_stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9fb5af-cb96-4213-ac03-63595317833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date        sales                station\n",
      "0  2023-01-01  1346.840438  Manchester Piccadilly\n",
      "1  2023-01-02  1347.696314  Manchester Piccadilly\n",
      "2  2023-01-03  1349.757360  Manchester Piccadilly\n",
      "3  2023-01-04  1354.646786  Manchester Piccadilly\n",
      "4  2023-01-05  1348.356770  Manchester Piccadilly \n",
      "\n",
      "       station    lat   lon       operator\n",
      "0   Abbey Wood  51.49  0.12   English Rail\n",
      "1     Aberdeen  57.14 -2.09  Scottish Rail\n",
      "2  Abergavenny  51.81 -3.00     Welsh Rail\n",
      "3  Aberystwyth  52.41 -4.08     Welsh Rail\n",
      "4   Accrington  53.75 -2.36   English Rail \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick peek at what's in the dataframes.\n",
    "for df in dataframes:\n",
    "    print(df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6959ae-8090-4659-8bf3-9f0f73697a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 70100 entries, 0 to 70099\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   date     70100 non-null  object \n",
      " 1   sales    70100 non-null  float64\n",
      " 2   station  70100 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1260 entries, 0 to 1259\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   station   1260 non-null   object \n",
      " 1   lat       1260 non-null   float64\n",
      " 2   lon       1260 non-null   float64\n",
      " 3   operator  1260 non-null   object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 49.2+ KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting basic info re: whether null values, data types abd volume.\n",
    "# WARNING!  There is a date column with data type \"object\"; this will be converted.\n",
    "for df in dataframes:\n",
    "    print(f\"{df.info()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1383493d-341a-474b-bad0-103e55337220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date from object to date.\n",
    "df_sales['date'] = pd.to_datetime(df_sales['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851e9be4-4f3c-4308-94a6-0541c81d8cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_name: station\n",
      " sorted_values: ['Aberdeen' 'Ashford International' 'Banbury' 'Basingstoke' 'Bath Spa'\n",
      " 'Bedford' 'Birmingham International' 'Birmingham New Street'\n",
      " 'Bishops Stortford' 'Bournemouth' 'Brighton' 'Bristol Parkway'\n",
      " 'Bristol Temple Meads' 'Cambridge' 'Cardiff Central' 'Carlisle'\n",
      " 'Chelmsford' 'Cheltenham Spa' 'Chester' 'Chesterfield' 'Chippenham'\n",
      " 'Clapham Junction' 'Colchester' 'Coventry' 'Crewe' 'Darlington'\n",
      " 'Didcot Parkway' 'Doncaster' 'Durham' 'East Croydon'\n",
      " 'Edinburgh (Waverley)' \"Exeter St David's\" 'Gatwick Airport'\n",
      " 'Glasgow Central' 'Glasgow Queen Street' 'Gloucester' 'Grantham'\n",
      " 'Guildford' 'Haymarket' 'Haywards Heath' 'Hull' 'Ipswich' 'Kettering'\n",
      " 'Lancaster' 'Leamington Spa' 'Leeds' 'Leicester' 'Lincoln'\n",
      " 'Liverpool Lime Street' 'London Bridge' 'London Euston'\n",
      " 'London Kings Cross' 'London Liverpool Street' 'London Marylebone'\n",
      " 'London Paddington' 'London St Pancras International' 'London Victoria'\n",
      " 'London Waterloo' 'Loughborough' 'Macclesfield' 'Manchester Airport'\n",
      " 'Manchester Piccadilly' 'Manchester Victoria' 'Market Harborough'\n",
      " 'Milton Keynes Central' 'Newark Northgate' 'Newcastle'\n",
      " 'Newport (South Wales)' 'Northampton' 'Norwich' 'Nottingham' 'Oxford'\n",
      " 'Peterborough' 'Plymouth' 'Preston (Lancs)' 'Reading' 'Rugby' 'Sheffield'\n",
      " 'Southampton Airport Parkway' 'Southampton Central' 'St Albans City'\n",
      " 'Stafford' 'Stansted Airport' 'Stevenage' 'Stockport' 'Stoke-on-Trent'\n",
      " 'Stratford (London)' 'Swansea' 'Swindon (Wilts)' 'Taunton'\n",
      " 'Tiverton Parkway' 'Wakefield Westgate' 'Warrington Bank Quay'\n",
      " 'Wigan North Western' 'Wilmslow' 'Winchester' 'Witham' 'Woking'\n",
      " 'Wolverhampton' 'York']\n",
      " unique_values: 100\n",
      "\n",
      "column_name: station\n",
      " sorted_values: ['Abbey Wood' 'Aberdeen' 'Abergavenny' ... 'Yeovil Junction'\n",
      " 'Yeovil Pen Mill' 'York']\n",
      " unique_values: 1259\n",
      "\n",
      "column_name: operator\n",
      " sorted_values: ['English Rail' 'Scottish Rail' 'Trainline' 'Welsh Rail']\n",
      " unique_values: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Above indicates no None/Nan values, but there may still be blanks or other placeholders indicating missing data.\n",
    "# There doesn't seem to be any unusual values in the df_sales station \n",
    "for df in dataframes:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            print(f'column_name: {df[col].name}\\n sorted_values: {(df[col].sort_values().unique())}\\n unique_values: {df[col].nunique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d336696f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "Aberdeen                           {}\n",
       "Ashford International              {}\n",
       "Banbury                            {}\n",
       "Basingstoke                        {}\n",
       "Bath Spa                           {}\n",
       "Bedford                            {}\n",
       "Birmingham International           {}\n",
       "Birmingham New Street              {}\n",
       "Bishops Stortford                  {}\n",
       "Bournemouth                        {}\n",
       "Brighton                           {}\n",
       "Bristol Parkway                    {}\n",
       "Bristol Temple Meads               {}\n",
       "Cambridge                          {}\n",
       "Cardiff Central                    {}\n",
       "Carlisle                           {}\n",
       "Chelmsford                         {}\n",
       "Cheltenham Spa                     {}\n",
       "Chester                            {}\n",
       "Chesterfield                       {}\n",
       "Chippenham                         {}\n",
       "Clapham Junction                   {}\n",
       "Colchester                         {}\n",
       "Coventry                           {}\n",
       "Crewe                              {}\n",
       "Darlington                         {}\n",
       "Didcot Parkway                     {}\n",
       "Doncaster                          {}\n",
       "Durham                             {}\n",
       "East Croydon                       {}\n",
       "Edinburgh (Waverley)               {}\n",
       "Exeter St David's                  {}\n",
       "Gatwick Airport                    {}\n",
       "Glasgow Central                    {}\n",
       "Glasgow Queen Street               {}\n",
       "Gloucester                         {}\n",
       "Grantham                           {}\n",
       "Guildford                          {}\n",
       "Haymarket                          {}\n",
       "Haywards Heath                     {}\n",
       "Hull                               {}\n",
       "Ipswich                            {}\n",
       "Kettering                          {}\n",
       "Lancaster                          {}\n",
       "Leamington Spa                     {}\n",
       "Leeds                              {}\n",
       "Leicester                          {}\n",
       "Lincoln                            {}\n",
       "Liverpool Lime Street              {}\n",
       "London Bridge                      {}\n",
       "London Euston                      {}\n",
       "London Kings Cross                 {}\n",
       "London Liverpool Street            {}\n",
       "London Marylebone                  {}\n",
       "London Paddington                  {}\n",
       "London St Pancras International    {}\n",
       "London Victoria                    {}\n",
       "London Waterloo                    {}\n",
       "Loughborough                       {}\n",
       "Macclesfield                       {}\n",
       "Manchester Airport                 {}\n",
       "Manchester Piccadilly              {}\n",
       "Manchester Victoria                {}\n",
       "Market Harborough                  {}\n",
       "Milton Keynes Central              {}\n",
       "Newark Northgate                   {}\n",
       "Newcastle                          {}\n",
       "Newport (South Wales)              {}\n",
       "Northampton                        {}\n",
       "Norwich                            {}\n",
       "Nottingham                         {}\n",
       "Oxford                             {}\n",
       "Peterborough                       {}\n",
       "Plymouth                           {}\n",
       "Preston (Lancs)                    {}\n",
       "Reading                            {}\n",
       "Rugby                              {}\n",
       "Sheffield                          {}\n",
       "Southampton Airport Parkway        {}\n",
       "Southampton Central                {}\n",
       "St Albans City                     {}\n",
       "Stafford                           {}\n",
       "Stansted Airport                   {}\n",
       "Stevenage                          {}\n",
       "Stockport                          {}\n",
       "Stoke-on-Trent                     {}\n",
       "Stratford (London)                 {}\n",
       "Swansea                            {}\n",
       "Swindon (Wilts)                    {}\n",
       "Taunton                            {}\n",
       "Tiverton Parkway                   {}\n",
       "Wakefield Westgate                 {}\n",
       "Warrington Bank Quay               {}\n",
       "Wigan North Western                {}\n",
       "Wilmslow                           {}\n",
       "Winchester                         {}\n",
       "Witham                             {}\n",
       "Woking                             {}\n",
       "Wolverhampton                      {}\n",
       "York                               {}\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique dates from df and for indiv stations printing if any dates are missing.\n",
    "all_dates = df_sales['date'].unique()\n",
    "missing_dates = (df_sales.groupby('station')['date'].apply(lambda x: set(all_dates) - set(x)))\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b51631fb-3a55-499c-81d8-b0c4fff1c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 date         sales                station\n",
      "count                           70100  70100.000000                  70100\n",
      "unique                            NaN           NaN                    100\n",
      "top                               NaN           NaN  Manchester Piccadilly\n",
      "freq                              NaN           NaN                    701\n",
      "mean    2023-12-17 00:00:00.000000256    337.535624                    NaN\n",
      "min               2023-01-01 00:00:00     92.314156                    NaN\n",
      "25%               2023-06-25 00:00:00    135.779942                    NaN\n",
      "50%               2023-12-17 00:00:00    200.444485                    NaN\n",
      "75%               2024-06-09 00:00:00    371.568482                    NaN\n",
      "max               2024-12-01 00:00:00   2754.247272                    NaN\n",
      "std                               NaN    390.673461                    NaN\n",
      "\n",
      "               station          lat          lon      operator\n",
      "count             1260  1260.000000  1260.000000          1260\n",
      "unique            1259          NaN          NaN             4\n",
      "top     Exeter Central          NaN          NaN  English Rail\n",
      "freq                 2          NaN          NaN           837\n",
      "mean               NaN    52.260913    -1.212143           NaN\n",
      "std                NaN     1.433910     1.397825           NaN\n",
      "min                NaN    50.120000    -5.530000           NaN\n",
      "25%                NaN    51.400000    -2.120000           NaN\n",
      "50%                NaN    51.510000    -0.865000           NaN\n",
      "75%                NaN    53.065000    -0.177500           NaN\n",
      "max                NaN    57.640000     1.740000           NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic stats and looking for flags.\n",
    "for df in dataframes:\n",
    "    print(f\"{df.describe(include = 'all')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12114f5-b10f-4100-915d-01260291b63e",
   "metadata": {},
   "source": [
    "Observations:\n",
    "+ Date range is for two years from 01/01/2023 to 1/12/2024.  n.b. month of December 2024 not present.\n",
    "+ 2024 has a leap year.  n.b. for prediction.\n",
    "+ Large range of sales, with standard deviation larger than the mean.\n",
    "+ Mean larger than median, indicating right skew distribution and possibility of outliers.\n",
    "+ Looks like each of the 100 stations appears 701 times, but needs verifying.\n",
    "+ The lookups have a duplicate, in exeter central, but this is not relevant to the df_sales stations list.\n",
    "+ Latitudes and longitudes seem sensible for GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df32d64-b8cb-4e25-8ba7-ea176cca3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identical entries: \n",
      " Empty DataFrame\n",
      "Columns: [date, sales, station]\n",
      "Index: [] \n",
      "\n",
      "Identical entries: \n",
      " Empty DataFrame\n",
      "Columns: [station, lat, lon, operator]\n",
      "Index: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates.\n",
    "# Whether same row of data is present more than once.\n",
    "for df in dataframes:\n",
    "    print('Identical entries: \\n', df[df.duplicated()], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba61426f-574d-4494-995d-0e18a693a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            station    lat   lon      operator\n",
      "388  Exeter Central  51.46 -0.90     Trainline\n",
      "389  Exeter Central  50.72 -3.53  English Rail \n",
      "\n",
      "            station    lat   lon      operator\n",
      "389  Exeter Central  50.72 -3.53  English Rail\n"
     ]
    }
   ],
   "source": [
    "# Tells us, not identical duplicated entry for exeter central, but two locations called this, with differnt info.\n",
    "# Google search indicates English Rail value is correct, so other removed from look ups.\n",
    "print(df_stations[df_stations['station']=='Exeter Central'], '\\n')\n",
    "df_stations = df_stations[~((df_stations['station']=='Exeter Central') & (df_stations['operator']=='Trainline'))]\n",
    "# Checking removal.\n",
    "print(df_stations[df_stations['station']=='Exeter Central'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74e8d2-b694-4fb7-ae78-a63ddb83a357",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e6b2e5-fed1-480a-910e-5ab18d6864aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some formatting amendments to prevent future issues.\n",
    "# Mainly removal of punctuation, case folding and removing spaces.\n",
    "df_sales['station_adj'] = df_sales['station'].str.lower().str.strip().str.replace('(', '').str.replace(\"'\", '').str.replace(' ', '_').str.replace(')', '').str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271bb5a-48e5-4bd5-ba8b-83cf659e32db",
   "metadata": {},
   "source": [
    "## GEODATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434a257",
   "metadata": {},
   "source": [
    "### DERIVING CODES FROM LONGITUDE-LATITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44f0326c-46ee-4af6-b540-282be40c9af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_25828\\3200932652.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stations['rgn'] = df_postcodes.iloc[indices.flatten()]['rgn'].values\n",
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_25828\\3200932652.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stations['ru11ind'] = df_postcodes.iloc[indices.flatten()]['ru11ind'].values\n"
     ]
    }
   ],
   "source": [
    "# Obtaining region, rurality and built up area code from lookups, based on nearest neighbours algorithm across longitudes and latitudes.\n",
    "# Would enable visualisation and analysis for region (or another geo level of choosing from postcodes lookup).\n",
    "# Would also allow matching with other third party data.\n",
    "\n",
    "# Renaming column, so aligned with dataset.\n",
    "df_postcodes = df_postcodes.rename(columns={\"long\": \"lon\"})\n",
    "\n",
    "# Using nearest neighbours.\n",
    "# Only want closest single value from lookup, so n_neighbours = 1\n",
    "# ball_tree best for continuous numeric data, as lon lat is; along with high dimensionality, its faster.\n",
    "nbrs = NearestNeighbors(n_neighbors = 1, algorithm = 'ball_tree').fit(df_postcodes[['lat','lon']])\n",
    "distances, indices = nbrs.kneighbors(df_stations[['lat','lon']])\n",
    "\n",
    "#  Adding the requested columns to the df_stations lookup.\n",
    "df_stations['rgn'] = df_postcodes.iloc[indices.flatten()]['rgn'].values\n",
    "df_stations['ru11ind'] = df_postcodes.iloc[indices.flatten()]['ru11ind'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0199e4b-4d47-43db-956d-e1ba0b406503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_25828\\1783026704.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_stations['bua'] = df_bua.iloc[indices.flatten()]['BUA22CD'].values\n"
     ]
    }
   ],
   "source": [
    "# Performing similar task, from a built up area lookup to determine whether area is coastal.\n",
    "\n",
    "# Renaming column, so aligned with dataset.\n",
    "df_bua.reset_index(inplace = True)\n",
    "df_bua.rename(columns={\"LONG\": \"lon\", \"LAT\": \"lat\"}, inplace= True)\n",
    "\n",
    "# Only want closest single value from lookup, so n_neighbours = 1\n",
    "# ball_tree best for continuous numeric data, as lon lat is; along with high dimensionality, its faster.\n",
    "nbrs = NearestNeighbors(n_neighbors = 1, algorithm = 'ball_tree').fit(df_bua[['lat','lon']])\n",
    "distances, indices = nbrs.kneighbors(df_stations[['lat','lon']])\n",
    "\n",
    "#  Adding the requested columns to the df_stations lookup.\n",
    "df_stations['bua'] = df_bua.iloc[indices.flatten()]['BUA22CD'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eab9e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>operator</th>\n",
       "      <th>rgn</th>\n",
       "      <th>ru11ind</th>\n",
       "      <th>bua</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbey Wood</td>\n",
       "      <td>51.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>English Rail</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>A1</td>\n",
       "      <td>E63004992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>57.14</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>Scottish Rail</td>\n",
       "      <td>S99999999</td>\n",
       "      <td>1</td>\n",
       "      <td>S45000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abergavenny</td>\n",
       "      <td>51.81</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>Welsh Rail</td>\n",
       "      <td>W99999999</td>\n",
       "      <td>F1</td>\n",
       "      <td>W45000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberystwyth</td>\n",
       "      <td>52.41</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>Welsh Rail</td>\n",
       "      <td>W99999999</td>\n",
       "      <td>C2</td>\n",
       "      <td>W45000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accrington</td>\n",
       "      <td>53.75</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>English Rail</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>C1</td>\n",
       "      <td>E63000864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station    lat   lon       operator        rgn ru11ind        bua\n",
       "0   Abbey Wood  51.49  0.12   English Rail  E12000007      A1  E63004992\n",
       "1     Aberdeen  57.14 -2.09  Scottish Rail  S99999999       1  S45000002\n",
       "2  Abergavenny  51.81 -3.00     Welsh Rail  W99999999      F1  W45000324\n",
       "3  Aberystwyth  52.41 -4.08     Welsh Rail  W99999999      C2  W45000228\n",
       "4   Accrington  53.75 -2.36   English Rail  E12000002      C1  E63000864"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current state of df after matching.\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e0a213-3931-4e04-b849-3d5b61f0e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick copy, to save me doing above again, in case I balls below up.\n",
    "df_x = df_stations.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139e3d5",
   "metadata": {},
   "source": [
    "### MAPPING CODES TO NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4839f5-3b71-483d-8b6a-d7f6b460ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGION\n",
    "# Bringing through region name to station table.\n",
    "# Tidying by renaming, dropping and formatting columns.\n",
    "df_stations = df_stations.merge(df_rgn.reset_index()[['RGN20CD', 'RGN20NM']], left_on = 'rgn', right_on = 'RGN20CD', how = 'left')\n",
    "df_stations.rename(columns = {'RGN20NM': 'region_nm'}, inplace = True)\n",
    "df_stations.drop(['RGN20CD'], axis = 1, inplace = True)\n",
    "df_stations['region_nm'] = df_stations['region_nm'].str.lower().str.replace('(pseudo) ', '').str.replace(' ', '_')\n",
    "\n",
    "# RURAL-URBAN\n",
    "# Bringing through name of rural-urban classification.\n",
    "# Remappping urban and rural to unify GB and for fewer groupings.\n",
    "df_stations = df_stations.merge(df_ru11ind, left_on = 'ru11ind', right_on = 'RU11IND', how = 'left')\n",
    "df_stations.rename(columns = {'RU11NM': 'rurality_nm'}, inplace = True)\n",
    "df_stations = df_stations.drop(columns=['RU11IND'])\n",
    "df_stations['rurality_nm'] = np.where(df_stations['rurality_nm'].isin(['(England/Wales) Urban major conurbation', '(Scotland) Large Urban Area']), 'urban_major_conurbation',\n",
    "                                      np.where(df_stations['rurality_nm'] == '(England/Wales) Urban minor conurbation', 'urban_minor_conurbation',\n",
    "                                            np.where(df_stations['rurality_nm'] == '(England/Wales) Urban city and town', 'urban_city_town',\n",
    "                                                    np.where(df_stations['rurality_nm'].isin(['(England/Wales) Rural hamlet and isolated dwellings', '(England/Wales) Rural village']), 'rural', 'unknown'))))\n",
    "                                                                                              \n",
    "# Obtaining whether area is coastal or not using bua code.\n",
    "# Data only available for England and Wales, so -1 for Scotland.\n",
    "df_stations['coastal_flag'] = np.where(df_stations['bua'].isin(df_coastal['BUA code']), 1,\n",
    "                                       np.where(df_stations['region_nm'] == 'scotland', -1, 0))\n",
    "\n",
    "# # Bringing through operator, region name, rurality code and coastal flag from station table to df_sales.\n",
    "df_sales = df_sales.merge(df_stations[['station', 'operator','region_nm', 'lat', 'lon', 'rurality_nm','coastal_flag']], on = 'station', how = 'left')\n",
    "df_sales['operator'] = df_sales['operator'].str.replace(' ', '_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b33204-4f29-4be6-ad79-9cd6125976a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>station</th>\n",
       "      <th>station_adj</th>\n",
       "      <th>operator</th>\n",
       "      <th>region_nm</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>rurality_nm</th>\n",
       "      <th>coastal_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1346.840438</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1347.696314</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1349.757360</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1354.646786</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1348.356770</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        sales                station            station_adj  \\\n",
       "0 2023-01-01  1346.840438  Manchester Piccadilly  manchester_piccadilly   \n",
       "1 2023-01-02  1347.696314  Manchester Piccadilly  manchester_piccadilly   \n",
       "2 2023-01-03  1349.757360  Manchester Piccadilly  manchester_piccadilly   \n",
       "3 2023-01-04  1354.646786  Manchester Piccadilly  manchester_piccadilly   \n",
       "4 2023-01-05  1348.356770  Manchester Piccadilly  manchester_piccadilly   \n",
       "\n",
       "       operator   region_nm    lat   lon              rurality_nm  \\\n",
       "0  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "1  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "2  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "3  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "4  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "\n",
       "   coastal_flag  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at sales table.\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b68c1-5c36-4814-8d02-240bbe65e3f1",
   "metadata": {},
   "source": [
    "## DATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981a47e-2251-41fd-8893-f586c4abc7a2",
   "metadata": {},
   "source": [
    "### GRANULARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9675bda0-6aee-45a3-9728-a9748ba669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns from date to indicate year, month, day of week, whether weekend and number of the week.\n",
    "# Intending to assist analysis and visualisation.\n",
    "df_sales['year'] = df_sales['date'].dt.year\n",
    "df_sales['month'] = df_sales['date'].dt.month\n",
    "df_sales['week_number'] = df_sales['date'].dt.isocalendar().week.astype('int')\n",
    "df_sales['day'] = df_sales['date'].dt.day\n",
    "df_sales['month_day'] = df_sales['date'].dt.strftime('%m-%d')  \n",
    "df_sales['week_day'] = (df_sales['date'].dt.day_name()).str.lower()\n",
    "df_sales['weekend_flag'] = df_sales['week_day'].isin(['saturday', 'sunday']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48ac711-9d0c-4710-b4bf-086573005acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>station</th>\n",
       "      <th>station_adj</th>\n",
       "      <th>operator</th>\n",
       "      <th>region_nm</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>rurality_nm</th>\n",
       "      <th>coastal_flag</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>month_day</th>\n",
       "      <th>week_day</th>\n",
       "      <th>weekend_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1346.840438</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>01-01</td>\n",
       "      <td>sunday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1347.696314</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01-02</td>\n",
       "      <td>monday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1349.757360</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>01-03</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1354.646786</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>01-04</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1348.356770</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>01-05</td>\n",
       "      <td>thursday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        sales                station            station_adj  \\\n",
       "0 2023-01-01  1346.840438  Manchester Piccadilly  manchester_piccadilly   \n",
       "1 2023-01-02  1347.696314  Manchester Piccadilly  manchester_piccadilly   \n",
       "2 2023-01-03  1349.757360  Manchester Piccadilly  manchester_piccadilly   \n",
       "3 2023-01-04  1354.646786  Manchester Piccadilly  manchester_piccadilly   \n",
       "4 2023-01-05  1348.356770  Manchester Piccadilly  manchester_piccadilly   \n",
       "\n",
       "       operator   region_nm    lat   lon              rurality_nm  \\\n",
       "0  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "1  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "2  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "3  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "4  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "\n",
       "   coastal_flag  year  month  week_number  day month_day   week_day  \\\n",
       "0             0  2023      1           52    1     01-01     sunday   \n",
       "1             0  2023      1            1    2     01-02     monday   \n",
       "2             0  2023      1            1    3     01-03    tuesday   \n",
       "3             0  2023      1            1    4     01-04  wednesday   \n",
       "4             0  2023      1            1    5     01-05   thursday   \n",
       "\n",
       "   weekend_flag  \n",
       "0             1  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at sales table.\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ece3e4-f8f1-4930-a887-60352f0968f9",
   "metadata": {},
   "source": [
    "### EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f52b9da9-4bf5-40bc-a430-b5814073f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank holidays\n",
    "# Creating dataframe to flag bank holidays according to region.\n",
    "# Those that have england-wales in region apply to all, whereas those with scotland in region are scotland only.\n",
    "\n",
    "# Sorting json file to convert to dateframe, with columns for date, region and name of holiday.\n",
    "bh_info = []\n",
    "for region, years in data_holidays.items():\n",
    "    for year, holidays in years.items():\n",
    "        for holiday in holidays:\n",
    "            bh_info.append({'title': holiday['title'],\n",
    "                            'date': pd.to_datetime(holiday['date']),\n",
    "                            'region': region})\n",
    "            \n",
    "df_holidays = pd.DataFrame(bh_info)\n",
    "\n",
    "# Creating separate dfs for ew and scottish holidays.\n",
    "holidays_scot = df_holidays[df_holidays['region'] == 'scotland']\n",
    "holidays_ew = df_holidays[df_holidays['region'] == 'england-and-wales']\n",
    "\n",
    "# If region is scotland, should flag for scottish plus englisha nd welsh holidays.\n",
    "sales_scot = df_sales[df_sales['region_nm'] == 'scotland']\n",
    "sales_scot = sales_scot.merge(pd.concat([holidays_scot, holidays_ew]), on = 'date', how = 'left')\n",
    "\n",
    "# Removing duplicates.\n",
    "sales_scot = sales_scot.drop_duplicates(subset=['station', 'date'])\n",
    "\n",
    "# If region isn't scotland, should flag for english and welsh holidays only.\n",
    "sales_ew = df_sales[df_sales['region_nm'] != 'scotland']\n",
    "sales_ew = sales_ew.merge(holidays_ew, on = 'date', how = 'left')\n",
    "\n",
    "# Recombining\n",
    "df_sales = pd.concat([sales_ew, sales_scot], ignore_index=True)\n",
    "df_sales['bank_holiday_flag'] = df_sales['title'].notna().astype(int)\n",
    "df_sales.drop(['title', 'region'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28be06fb-a2b6-4b58-a02b-8341490d73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Similar to above for strikes.\n",
    "#  To be revisited, ran out of time.\n",
    "# # Strikes\n",
    "# # Creating column that flags if the date was the date of an official train strike.\n",
    "# # Limitation:  Does not account for region specific strikes.\n",
    "# rows = []\n",
    "# for entry in data_strikes[\"train_strikes\"]:\n",
    "#     for d in entry[\"dates\"]:\n",
    "#         rows.append({\n",
    "#             \"date\": pd.to_datetime(d[\"date\"]),  # use the string\n",
    "#             \"union\": d[\"union\"]\n",
    "#         })\n",
    "\n",
    "# df_strikes = pd.DataFrame(rows)\n",
    "# df_sales['strike_flag'] = df_sales['date'].isin(df_strikes['date']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da59977-9011-4c04-ab61-610b9568de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column to flag if working day, based on weekend and bank holiday flag.\n",
    "df_sales['working_day'] = np.where(((df_sales['weekend_flag'] == 1)|(df_sales['bank_holiday_flag'] == 1)), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec295f13-7862-495d-9e21-3a9284c86a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>station</th>\n",
       "      <th>station_adj</th>\n",
       "      <th>operator</th>\n",
       "      <th>region_nm</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>rurality_nm</th>\n",
       "      <th>coastal_flag</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day</th>\n",
       "      <th>month_day</th>\n",
       "      <th>week_day</th>\n",
       "      <th>weekend_flag</th>\n",
       "      <th>bank_holiday_flag</th>\n",
       "      <th>working_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1346.840438</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>01-01</td>\n",
       "      <td>sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1347.696314</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01-02</td>\n",
       "      <td>monday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1349.757360</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>01-03</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1354.646786</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>01-04</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1348.356770</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>manchester_piccadilly</td>\n",
       "      <td>english_rail</td>\n",
       "      <td>north_west</td>\n",
       "      <td>53.47</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>urban_major_conurbation</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>01-05</td>\n",
       "      <td>thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        sales                station            station_adj  \\\n",
       "0 2023-01-01  1346.840438  Manchester Piccadilly  manchester_piccadilly   \n",
       "1 2023-01-02  1347.696314  Manchester Piccadilly  manchester_piccadilly   \n",
       "2 2023-01-03  1349.757360  Manchester Piccadilly  manchester_piccadilly   \n",
       "3 2023-01-04  1354.646786  Manchester Piccadilly  manchester_piccadilly   \n",
       "4 2023-01-05  1348.356770  Manchester Piccadilly  manchester_piccadilly   \n",
       "\n",
       "       operator   region_nm    lat   lon              rurality_nm  \\\n",
       "0  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "1  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "2  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "3  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "4  english_rail  north_west  53.47 -2.23  urban_major_conurbation   \n",
       "\n",
       "   coastal_flag  year  month  week_number  day month_day   week_day  \\\n",
       "0             0  2023      1           52    1     01-01     sunday   \n",
       "1             0  2023      1            1    2     01-02     monday   \n",
       "2             0  2023      1            1    3     01-03    tuesday   \n",
       "3             0  2023      1            1    4     01-04  wednesday   \n",
       "4             0  2023      1            1    5     01-05   thursday   \n",
       "\n",
       "   weekend_flag  bank_holiday_flag  working_day  \n",
       "0             1                  0            0  \n",
       "1             0                  1            0  \n",
       "2             0                  0            1  \n",
       "3             0                  0            1  \n",
       "4             0                  0            1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state of df_sales.\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445f4ea-6f38-437b-afd7-d37f37891291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exporting raw df.\n",
    "df_sales.to_csv('sales_processed.csv', index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311eaca5-924f-43e4-942a-91fb1b2a85e1",
   "metadata": {},
   "source": [
    "# UPLIFT MODELLING - PROPENSITY SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027e3b5-45b4-48c5-9da6-249d3cdaf5bd",
   "metadata": {},
   "source": [
    "This is the preferred option for the following reasons:\n",
    "+ Limited number of features to stop overfitting.\n",
    "+ Gives an average treatment effect.\n",
    "+ Not huge volume of data; only one point per day for the treatment.\n",
    "+ Nottingham billboard choice with costs likely wasn't random.\n",
    "\n",
    "However, a two-model approach might be better to target campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e93f38aa-7360-4e6b-823b-87f002ed1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Nottingham as the treatment.\n",
    "df_sales['treatment'] = (df_sales['station'] == 'Nottingham').astype(int)\n",
    "# Getting pre-period dataframe section.\n",
    "pre_period = df_sales[(df_sales['date'] >= '2023-10-01') & (df_sales['date'] < '2024-10-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c08723de-a5d4-4b2f-9970-f31b1ef51dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining control groups.\n",
    "df_uplift_east_midlands = pre_period[pre_period['region_nm'] == 'east_midlands']\n",
    "df_uplift_mid_north = pre_period[(pre_period['region_nm'].isin(['east_midlands', 'west_midlands', 'yorkshire_and_the_humber', 'east_of_england']))]\n",
    "df_uplift_mid_north_no_big = pre_period[(pre_period['region_nm'].isin(['east_midlands', 'west_midlands', 'yorkshire_and_the_humber', 'east_of_england'])) & (~pre_period['station_adj'].isin(['birmingham_new_street', 'leeds']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8ca1f06-11ae-4816-bfb2-de3a863f6e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_24764\\3541405557.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['propensity_score'] = best_xgb.predict_proba(X)[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ROC-AUC: 0.49999999999999994\n",
      "cv ROC-AUC: 0.4820319626278883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_24764\\3541405557.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['propensity_score'] = best_xgb.predict_proba(X)[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ROC-AUC: 0.8714285714285714\n",
      "cv ROC-AUC: 0.8711163153786103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysha\\AppData\\Local\\Temp\\ipykernel_24764\\3541405557.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['propensity_score'] = best_xgb.predict_proba(X)[:, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ROC-AUC: 0.8636363636363636\n",
      "cv ROC-AUC: 0.862155136801903\n"
     ]
    }
   ],
   "source": [
    "# Creating a model run that will run through each of the dataframes, preprocess the data, apply the xgboost model and generate uplift score.\n",
    "\n",
    "# Creating list of dataframes\n",
    "uplift_dataframes = [df_uplift_east_midlands, df_uplift_mid_north, df_uplift_mid_north_no_big]\n",
    "\n",
    "# Defining features to be used.\n",
    "variables = ['region_nm', 'coastal_flag', 'week_day', 'bank_holiday_flag']\n",
    "\n",
    "# Loop running through each of the dataframes.\n",
    "outputs = []\n",
    "for df in uplift_dataframes:\n",
    "    # One hot encodign categorical features.\n",
    "    X = pd.get_dummies(df[variables], \n",
    "                       columns=['region_nm', 'week_day'], \n",
    "                       drop_first=True)\n",
    "    y = df['treatment']\n",
    "\n",
    "    # Deifning xgboost.\n",
    "    xgb = XGBClassifier(eval_metric = 'logloss', random_state = 2025)\n",
    "\n",
    "    # Adding a very small grid of hyperparameters.\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 1000],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # Adding a 5-fold cross-validation full grid search.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        verbose=0,\n",
    "        n_jobs=-1)\n",
    "\n",
    "    # Fitting the grid.\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Predicting propensity scores\n",
    "    best_xgb = grid_search.best_estimator_\n",
    "    df['propensity_score'] = best_xgb.predict_proba(X)[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y, best_xgb.predict_proba(X)[:,1])\n",
    "    print(\"training ROC-AUC:\", train_auc)\n",
    "    print(\"cv ROC-AUC:\", grid_search.best_score_)\n",
    "\n",
    "    # Splitting into treated and control\n",
    "    treated = df[df['treatment'] == 1]\n",
    "    control = df[df['treatment'] == 0]\n",
    "\n",
    "    # Nearest neighbor matching\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(control[['propensity_score']])\n",
    "    distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "    matched_controls = control.iloc[indices.flatten()]\n",
    "\n",
    "    # Campaign period sales\n",
    "    campaign_period = df_sales[(df_sales['date'] >= '2024-10-01') & (df_sales['date'] <= '2024-12-01')]\n",
    "    treated_sales = campaign_period[campaign_period['station'] == 'Nottingham']['sales'].mean()\n",
    "    control_sales = campaign_period[campaign_period['station'].isin(matched_controls['station'])]['sales'].mean()\n",
    "\n",
    "    # Calculating uplift\n",
    "    uplift = treated_sales - control_sales\n",
    "    uplift_perc = (uplift / control_sales) * 100 if control_sales != 0 else None\n",
    "        \n",
    "    outputs.append({\n",
    "        'treatment sales': treated_sales,\n",
    "        'control sales': control_sales,\n",
    "        'uplift': uplift,\n",
    "        'uplift_perc' : uplift_perc,\n",
    "        'cv_roc': grid_search.best_score_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ac06329-c28c-4a2d-acb4-6b0bce127d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   treatment sales  control sales      uplift  uplift_perc    cv_roc\n",
      "0       566.487517     236.078161  330.409356   139.957611  0.482032\n",
      "1       566.487517     401.382577  165.104940    41.134058  0.871116\n",
      "2       566.487517     401.382577  165.104940    41.134058  0.862155\n"
     ]
    }
   ],
   "source": [
    "# Convert to summary DataFrame\n",
    "summary_df = pd.DataFrame(outputs)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6cc64-8e26-4d41-b5fa-10c5c25570d7",
   "metadata": {},
   "source": [
    "# BASIC ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61d090-20a8-4a59-90de-9fe257c6f194",
   "metadata": {},
   "source": [
    "## PROPORTIONS OF SALES BY GROUPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59179c8a-ec59-4c1d-9563-644eaa2078e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping = ['operator', 'region_nm', 'station']\n",
    "dataframe = {}\n",
    "for group in grouping:\n",
    "    df_group = pd.DataFrame(df_sales.groupby(group)['sales'].sum().div(df_sales['sales'].sum()).mul(100)).reset_index().sort_values(by='sales', ascending=False).reset_index(drop=True)\n",
    "    dataframe[group] = df_group\n",
    "    # print(dataframe[group], '\\n')\n",
    "\n",
    "df_operator = dataframe['operator']\n",
    "df_rgn_nm  = dataframe['region_nm']\n",
    "df_station = dataframe['station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994c4a0-2620-428f-8a5c-b10ec9c1339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operator</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english_rail</td>\n",
       "      <td>92.550537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scottish_rail</td>\n",
       "      <td>5.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>welsh_rail</td>\n",
       "      <td>2.024063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        operator      sales\n",
       "0   english_rail  92.550537\n",
       "1  scottish_rail   5.425400\n",
       "2     welsh_rail   2.024063"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5484bb8-92a5-4ac4-bab0-07e8bb1ef088",
   "metadata": {},
   "source": [
    "## PROPORTIONS OF SALES BY YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a176729c-98f7-4649-af31-14bfed295a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one day in December 2024, so removing December from comparisions.\n",
    "df_sales_no_dec = df_sales[df_sales['month'] != 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16b43016-d789-489b-b9e6-d0d5dc2c4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>index</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>change_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sales</td>\n",
       "      <td>1.111541e+07</td>\n",
       "      <td>1.148198e+07</td>\n",
       "      <td>3.297878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year  index          2023          2024  change_perc\n",
       "0     sales  1.111541e+07  1.148198e+07     3.297878"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting annual sales by year with % change.\n",
    "# Grouping by month and year to get total sales.\n",
    "annual_sales = df_sales_no_dec.groupby(['year'])['sales'].sum().reset_index()\n",
    "\n",
    "# Pivoting for annual difference\n",
    "pivot_sales = annual_sales.set_index('year').T\n",
    "\n",
    "# Calculating % change.\n",
    "pivot_sales['change_perc'] = 100 * (pivot_sales[2024] / pivot_sales[2023] - 1)\n",
    "pivot_sales.reset_index(inplace = True)\n",
    "pivot_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eff6a2e5-1bac-4c80-a193-ac8aa43d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting annual sales by year with % change, broken down by groupings.\n",
    "grouping = ['operator', 'region_nm', 'station']\n",
    "dataframes = {}\n",
    "\n",
    "for group in grouping:\n",
    "    annual_sales = (df_sales_no_dec.groupby([group, 'year'])['sales'].mean().reset_index())\n",
    "    pivot_sales = annual_sales.pivot_table(index=group,columns='year',values='sales')\n",
    "    pivot_sales['change_perc'] = ((pivot_sales[2024] / pivot_sales[2023] - 1) * 100)\n",
    "    pivot_sales.reset_index(inplace=True)\n",
    "    dataframes[group] = pivot_sales\n",
    "\n",
    "df_operator = dataframes['operator']\n",
    "df_rgn_nm   = dataframes['region_nm']\n",
    "df_station  = dataframes['station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59ba8fec-619d-4308-9689-90c4a8243cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>region_nm</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>change_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>east_midlands</td>\n",
       "      <td>195.806508</td>\n",
       "      <td>203.991654</td>\n",
       "      <td>4.180222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>east_of_england</td>\n",
       "      <td>229.678026</td>\n",
       "      <td>235.113540</td>\n",
       "      <td>2.366580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>london</td>\n",
       "      <td>804.218862</td>\n",
       "      <td>818.808929</td>\n",
       "      <td>1.814191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north_east</td>\n",
       "      <td>382.420941</td>\n",
       "      <td>414.159194</td>\n",
       "      <td>8.299298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>north_west</td>\n",
       "      <td>307.617981</td>\n",
       "      <td>316.547014</td>\n",
       "      <td>2.902637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scotland</td>\n",
       "      <td>358.382239</td>\n",
       "      <td>364.172628</td>\n",
       "      <td>1.615702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south_east</td>\n",
       "      <td>230.011298</td>\n",
       "      <td>237.797558</td>\n",
       "      <td>3.385164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south_west</td>\n",
       "      <td>225.777191</td>\n",
       "      <td>234.512263</td>\n",
       "      <td>3.868891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wales</td>\n",
       "      <td>223.433987</td>\n",
       "      <td>232.892853</td>\n",
       "      <td>4.233405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>west_midlands</td>\n",
       "      <td>279.949848</td>\n",
       "      <td>291.511041</td>\n",
       "      <td>4.129737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yorkshire_and_the_humber</td>\n",
       "      <td>433.267761</td>\n",
       "      <td>446.783027</td>\n",
       "      <td>3.119380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year                 region_nm        2023        2024  change_perc\n",
       "0                east_midlands  195.806508  203.991654     4.180222\n",
       "1              east_of_england  229.678026  235.113540     2.366580\n",
       "2                       london  804.218862  818.808929     1.814191\n",
       "3                   north_east  382.420941  414.159194     8.299298\n",
       "4                   north_west  307.617981  316.547014     2.902637\n",
       "5                     scotland  358.382239  364.172628     1.615702\n",
       "6                   south_east  230.011298  237.797558     3.385164\n",
       "7                   south_west  225.777191  234.512263     3.868891\n",
       "8                        wales  223.433987  232.892853     4.233405\n",
       "9                west_midlands  279.949848  291.511041     4.129737\n",
       "10    yorkshire_and_the_humber  433.267761  446.783027     3.119380"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rgn_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d757c3a7-7060-4367-a8da-c94f05b330fa",
   "metadata": {},
   "source": [
    "## PROPORTIONS OF SALES BY MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "189d1f7f-845c-4e1b-b0b4-38227084e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>change_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>320.766739</td>\n",
       "      <td>330.478114</td>\n",
       "      <td>3.027550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>322.137457</td>\n",
       "      <td>330.635116</td>\n",
       "      <td>2.637899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>326.802896</td>\n",
       "      <td>334.168037</td>\n",
       "      <td>2.253695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>332.044709</td>\n",
       "      <td>339.790915</td>\n",
       "      <td>2.332880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>335.940299</td>\n",
       "      <td>344.782236</td>\n",
       "      <td>2.631996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>337.866271</td>\n",
       "      <td>347.072367</td>\n",
       "      <td>2.724775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>338.131506</td>\n",
       "      <td>347.417067</td>\n",
       "      <td>2.746139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>337.555296</td>\n",
       "      <td>347.919333</td>\n",
       "      <td>3.070323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>336.896102</td>\n",
       "      <td>349.653699</td>\n",
       "      <td>3.786804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>336.856948</td>\n",
       "      <td>350.066990</td>\n",
       "      <td>3.921558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>335.077581</td>\n",
       "      <td>347.868847</td>\n",
       "      <td>3.817404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year  month        2023        2024  change_perc\n",
       "0         1  320.766739  330.478114     3.027550\n",
       "1         2  322.137457  330.635116     2.637899\n",
       "2         3  326.802896  334.168037     2.253695\n",
       "3         4  332.044709  339.790915     2.332880\n",
       "4         5  335.940299  344.782236     2.631996\n",
       "5         6  337.866271  347.072367     2.724775\n",
       "6         7  338.131506  347.417067     2.746139\n",
       "7         8  337.555296  347.919333     3.070323\n",
       "8         9  336.896102  349.653699     3.786804\n",
       "9        10  336.856948  350.066990     3.921558\n",
       "10       11  335.077581  347.868847     3.817404"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting monthly sales by year with % change.\n",
    "# Grouping by month and year to get total sales.\n",
    "monthly_sales = df_sales_no_dec.groupby(['year','month'])['sales'].mean().reset_index()\n",
    "\n",
    "# Pivoting for annual difference\n",
    "pivot_sales = monthly_sales.pivot(index = 'month', columns = 'year', values = 'sales')\n",
    "\n",
    "# Calculating % change.\n",
    "pivot_sales['change_perc'] = 100 * (pivot_sales[2024] / pivot_sales[2023] - 1)\n",
    "pivot_sales.reset_index(inplace = True)\n",
    "pivot_sales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
